\documentclass{article}

\usepackage{epcc}
\usepackage{url}
\PassOptionsToPackage{hyphens}{url}
\usepackage[colorlinks=false, hidelinks]{hyperref}
\usepackage{amsmath}
\usepackage[toc,page]{appendix}
\usepackage[table]{xcolor}
\usepackage[marginparsep=30pt]{geometry}
\usepackage{stmaryrd}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{tabu}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{fancyref}
\usepackage{relsize}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{diagbox}
\usepackage{multirow}
\usepackage{slashbox}
\usepackage{graphics}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{csquotes}

\usetikzlibrary{%
    arrows,
    arrows.meta,
    decorations,
    backgrounds,
    positioning,
    fit,
    petri,
    shadows,
    datavisualization.formats.functions,
    calc,
    shapes,
    shapes.multipart,
    matrix,
    plotmarks
}

\usepgfplotslibrary{fillbetween, statistics, dateplot}

\pgfplotsset{%
  compat=1.3,
  every non boxed x axis/.style={%
  enlarge x limits=false,
  x axis line style={}%-stealth},
  },
  every boxed x axis/.style={},
  every non boxed y axis/.style={%
  enlarge y limits=false,
  y axis line style={}%-stealth},
  },
  every boxed y axis/.style={},
}

\renewcommand{\labelenumii}{\theenumii}
\renewcommand{\theenumii}{\theenumi.\arabic{enumii}.}

\bibliographystyle{plainnat}
\bibpunct{(}{)}{;}{a}{,}{,}

\begin{document}

\pagenumbering{roman}

\title{Deep Learning on SpiNNaker: Report}
\author{Jonas Fassbender \\ \textit{jonas@fassbender.dev}}
\date{}

\makeEPCCtitle

\newpage

\begin{abstract}
\end{abstract}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction} % {{{

According to the SpiNNaker project's website:
\begin{displayquote}
  SpiNNaker is a novel massively-parallel computer
  architecture, inspired by the fundamental structure and
  function of the human brain, which itself is composed of
  billions of simple computing elements, communicating
  using unreliable spikes \citep{spinn_proj}.
\end{displayquote}
SpiNNaker is targeted at three main areas of research:
(\romannumeral 1) neuroscience: understanding the human
brain, (\romannumeral 2) robotics: low power hardware and
(\romannumeral 3) computer science: new approach to
supercomputing and massive parallelism.
The dissertation project, which this paper reports on,
will concern itself with (\romannumeral 3) and one of the
research areas of computer science, which has emerged as
a driving force behind advancements in many fields and for
many tasks like speech and image recognition, drug
discovery and genomics: deep learning
\citep{lecun_et_al_2015}.

While deep learning is a promising field and deep neural
networks at the center of important advancements, like
described above, they face a major problem: the sheer
amount of computation needed for training them.
Researchers at OpenAI have estimated, that the amount of
computation needed for training state of the art deep
neural networks increases exponentially, doubling every
3.4 months \citep{openai2019}.
In order to cope with such unprecedented amounts of
computation and energy needed, the search for specialized
hardware is well underway.
Current state of the art hardware for accelerating the
training of deep neural networks are ASICs like TPUs and
general purpose GPUs \citep{tpus, mittal_et_al_2019}.

The goal of the dissertation project that is introduced in
this paper, will be to analyze if SpiNNaker could be an
energy efficient, scalable and fast alternative to the
above mentioned hardware.
Since deep neural networks are derived from the human
brain and nerve system \citep{goodfellow2016} and SpiNNaker
was designed to model the human brain, it seems rather
probable, that SpiNNaker will be a good target for
accelerating the training of deep neural networks.

This paper concerns itself with the dissertation project:
``Deep Learning on SpiNNaker'', which will be conducted in
the period from May 2019 to August 2019 as the final work
of the author to achieve his Master of Science in
High Performance Computing with Data Science from the
University of Edinburgh.
The report is mostly a summary of the preliminary work
conducted in the months before the actual work on the
disseration will be conducted.

The finindings of the preliminary work and the changes made
to the original project scope are the focal point of this
report.
The original title of the disseration project was ``A
Tensorflow Backend to SpiNNaker'', but the preliminary work
conducted to this point show, that the scope will be
redirected from implementing a backend for tensorflow---a
library for running fast linear algebra operations on
distributed, heterogenous systems, mainly designed for
implementing computationally demanding machine learning
algorithms like deep learning in a fast manner
\citep{tf2015}---to an approach focused on implementing
deep learning directly on SpiNNaker.
Because of SpiNNaker's specialized design, which works
rather contrary to that of tensorflow and current hardware
trends for building accelerators for deep learning,
interfacing between SpiNNaker's runtime and tensorflow was
deemed too difficult and not beneficial.
Instead, this dissertation aims at implementing deep
learning directly on SpiNNaker, providing an interface to
the well known deep learning library Keras \citep{keras}.
\citet{proj} shows the original disseration project's
scope.

This paper starts with presenting a brief outline of the
background of the dissertation, providing a discription of
the technologies important in this report: SpiNNaker, deep
learning and tensorflow in Section~\ref{sec:background}.
Also, the updated goal for the dissertation is given.
Afterwards, in Section~\ref{sec:related_work}, some
papers and other literature crucial for the further doings
for this project are presented.
The paper continues by giving a work plan in
Section~\ref{sec:work_plan}, before presenting a risk
analysis in Section~\ref{sec:risk_analysis}.
Afterwards the preliminary findings outlined above are
disscussed in more depth in Section~\ref{sec:prelim}.
At last, Section~\ref{sec:proposal} gives the final
project proposal and Section~\ref{sec:review} will contain
a review of a related dissertation project done in 2018:
``Deep Learning Performance on Different Architectures'' by
Spyro Nita \citep{nita_2018}.

% }}}

\section{Background} % {{{
\label{sec:background}

% TODO: pictures of SpiNNaker

% paragraph on spiking neural networks

% very general view of DNNs

% very general view of tensorflow

% benchmark idea

% }}}

\section{Related Work} % {{{
\label{sec:related_work}

% TODO: benchmark papers

% }}}

\section{Work Plan} % {{{
\label{sec:work_plan}

% }}}

\section{Risk Analysis} % {{{
\label{sec:risk_analysis}

% }}}

\section{Preliminary Findings} % {{{
\label{sec:prelim}

% main problem will be programming

% => minimize everything that is not programming
%    (benchmarking: use other benchmarks, ...)

% tf backend too difficult (XLA, linear algebra not what
% spinnaker was designed for)

% }}}

\section{Final Project Proposal} % {{{
\label{sec:proposal}

% describe the benchmark

% implement subset of keras api to make benchmark possible

% }}}

\section{Deep Learning Performance on Different % ... {{{
  Architectures: Review}
\label{sec:review}

This section will concern itself with a review of the
dissertation of Spyro Nita, which he did for earning his
Master of Science in High Performance Computing with Data
Science at the University of Edinburgh:
``Deep Learning Performance on Different Architectures''
 \citep{nita_2018}.
First, a summary of his dissertation will be given, before
the review of his work is presented.
The review will start by looking at how well the context
of the dissertation is explained and how well the scope
of the dissertation's problem is defined.
The last part of the review will be the consideration of
the dissertation's layout and formatting.
After the review, the importance of the dissertation for
``Deep Learning on SpiNNaker'' will be discussed and
evaluated.

\citet{nita_2018} concerns itself with measuring the
computational performance of two different approaches for
training deep neural networks: (\romannumeral 1)
distributed training using GPUs and (\romannumeral 2)
distributed training using CPUs.
The dissertation is a work derived of the efforts of
Team EPCC at the Student Cluster Competition at the
International Supercomputing Conference 2018, held in
Frankfurt, where Team EPCC competed against other teams by
building a small supercomputing cluster and running various
benchmarks on it, to see which team built the best
supercomputing cluster.
One of these benchmarks concerned itself with measuring the
performance of training a deep neural network on the
clusters, which is picked up in \citet{nita_2018} and
represents the benchmark for approach (\romannumeral 1).

The benchmark is based on the famous ImageNet dataset,
which consists of more than 14 million images, organized
according to the WordNet hierarchy into over 21 thousand
so called synsets (synonym sets) \citep{imagenet, wordnet}.
Contrary to the annual Large Scale Visual Recognition
Challenge (ILSVRC)---a benchmark also based on the ImageNet
dataset; the de-facto standard for benchmarking image
recognition models---the benchmark for the Student Cluster
Competition only concerns itself with the throughput of
images during training and not with the accuracy of the
trained models.
The througput is measured in images per second.
Only if two teams should have the same throughput during
training is the training accuracy taken into account as
the secondary criterion for tie-breaking.
The teams participating in the Student Cluster Competition
had to train the VGG16 deep neural network---a famous
model architecture introduced in the ILSVRC 2014 by
researchers from Oxford University
\citep{simonyan_et_al_2014}---on 1000 synsets containing
1.2 million images.
The main limitation for the clusters were their power
budget of 3kW and---for the ImageNet benchmark---a maximum
runtime of three hours \citep{nita_2018}.

\citet{nita_2018} compares the throughput of the
supercomputing cluster of Team EPCC for the performance of
a distributed GPU system against Cirrus---a supercomputer
hosted by the EPCC---for the performance of a distributed
CPU system \citep{cirrus}.

Concerning the results of \citet{nita_2018}, two major
problems were encountered: (\romannumeral 1) cluster
damage and failure of the Team EPCC cluster shortly before
the competition and (\romannumeral 2) the fact that the CPU
benchmark on Cirrus could not be distributed over multiple
backend nodes.
Fortunately benchmarks were done on the Team EPCC cluster,
before its failure and \citet{nita_2018} presents the
results of using the first node of the cluster with six
NVIDIA V100 GPUs.
Concerning (\romannumeral 2), \citet{nita_2018} presents
the results for a single backend node and assumes that
Cirrus would be able to linearly scale to multiple backend
nodes, when comparing the two clusters.
The single node of the Team EPCC cluster with its six
NVIDIA V100 GPUs generates a throughput of 2,052 images per
second, while a single backend node of Cirrus (two Intel
Xeon E5-2695 processors, each with 18 physical cores) can
generate a throughput of just 18 images per second.
Assuming linear scaling over multiple backend nodes of
Cirrus, 21 nodes would be needed for the throughput of a
single NVIDIA V100 GPU.
\citet{nita_2018} concludes that GPUs offer a significant
advantage compared to CPUs, when it comes to training
deep neural networks.

The dissertation starts with an introduction, which
includes a description of the dissertation's layout.
The second chapter concerns itself with a description of
convolutional neural networks for image classification,
describing ImageNet and VGG16 as a special convolutional
neural network.
Chapter three describes everything concerning the Student
Cluster Competition, including the benchmarks, rules and
various features of the Team EPCC cluster, including the
used hardware, operating system and other important
software libraries.
It also describes the difficulties and hardware damage to
the cluster and---concerning the ImageNet benchmark---how
the images were preprocessed and reformatted to the
TFRecord format \citep{tf2015}.
Chapter four concerns itself with the optimization of the
VGG16 neural network, mainly through different parameters
which are passed to tensorflow, which is used for
implementing VGG16.
It thoroughly describes how one can distribute training
across multiple GPUs.
The benchmark for the Student Cluster Competition is
described and analyzed, as is the benchmark for Cirrus.
The chapter ends by comparing both.
\citet{nita_2018} concludes by summarizing the results
presented in chapter four and gives an outline for future
work, which could shed more light on the performance of
GPU and CPU clusters for training deep neural networks.
The two main points of emphasis for future work presented
are: (\romannumeral 1) scaling training to hundreds of
CPU nodes \citep[see e.g.][for distributing training onto
multiple CPUs]{you2017} and (\romannumeral 2)
comparing power consumption of CPU nodes against GPU nodes.

The best thing to say about \citet{nita_2018} is how well
the whole experience of the Student Cluster Competition is
communicated by the author.
\citet{nita_2018} does not simply give a description of
everything that is important for the benchmark, but gives
a very conclusive and elaborate review of the whole
competition.
It serves as a red line throughout the whole dissertation.

Chapter four contains the benchmark and its results.
It is a conclusive chapter and well annotated with useful
references.
The difficulties of the environment are clearly described
and while there were failures and the benchmarks on both
the cluster of Team EPCC and Cirrus are not optimal, these
difficulties are discussed openly and the presented results
are sensible.

Overall, \citet{nita_2018} describes the context and
problem scope well.
Its only problem is, it does not make it easy for the
reader to see that.
The layout can only be described as cluttered and a few
passages and paragraphs are simply unnecessary.
For example, Chapter~3.4 does not belong in the chapter
that concerns itself with the Student Cluster Competition,
if it belongs into the dissertation at all.
While the chosen data format could be seen as an
optimization and therefore should be described in chapter
four, problems during the download before the competition
are irrelevant to the benchmark.
Also chapter three and two could be swapped, which would
have made for an easier introduction to the dissertation,
where one is first confronted by the whole context and
rather gentle chapter about the Student Cluster
Competition, instead of by a description of convolutional
neural networks and ImageNet.
The first paragraph of the introduction to the dissertation
is just weird and seems to pay homage to
\citet{goodfellow2016}, which also starts with a similarly
weird introduction about Greek mythology and the craving of
humankind for thinking machines.

A second point of critique could be the absence of a
chapter on related work, which gives a rough overview of
other, comparable benchmarks.
Some other benchmarks, like \citet{you2017}, are referenced
in the dissertation, but the reader does not get a general
overview over what else is out there.

\citet{nita_2018} and ``Deep Learning on SpiNNaker''
overlap in their problem scope, in the sense that both
concern itself with benchmarking the training speed of
deep neural networks.
Both focusing on image recognition based on the ImageNet
dataset.
While probably not directly important for the benchmark
conducted as part of ``Deep Learning on SpiNNaker'',
since \citet{nita_2018} benchmarks the VGG16 model and
``Deep Learning on SpiNNaker'' will focus on ResNet50 and
AlexNet (see Section~\ref{sec:proposal}),
\citet{nita_2018} still provided a great first point of
reference for the literature review done so far.

% }}}

\bibliography{library.bib}

\end{document}
