\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{stmaryrd}
\usepackage{tikz}
\usepackage{listings}
\usepackage{graphics}

%\usetheme{Warsaw}

\usetikzlibrary{%
    arrows,
    arrows.meta,
    decorations,
    backgrounds,
    positioning,
    fit,
    petri,
    shadows,
    datavisualization.formats.functions,
    calc,
    shapes,
    shapes.multipart,
    matrix
}

\bibliographystyle{alpha}


\begin{document}

% titlepage {{{
\begin{frame}
\begin{center}
{\Large A tensorflow backend to SpiNNaker }

More precisely: a keras backend to SpiNNaker

\vspace{2cm}

Jonas Fassbender

\vspace{2cm}

Supervisors:

Alan Stokes, Kevin Stratford, Caoimh√≠n Laoide-Kemp

\end{center}
\end{frame}
% }}}

% What is SpiNNaker? {{{
\begin{frame}[fragile]
  \frametitle{What is SpiNNaker?}
  \setbeamercovered{invisible}
  \pause

  The project's website \cite{spinnaker_project} states:

  \textcolor{white}{bad workaround}

  [SpiNNaker is] a platform for high-performance massively
  parallel [and energy efficient] processing appropriate
  for the simulation of large-scale [spiking] neural
  networks [\dots]

\end{frame}
% }}}

% Why use SpiNNaker as a target for training deep NNs? {{{
\begin{frame}[fragile]
  \frametitle{Why use SpiNNaker as a target for training deep NNs?}
  \setbeamercovered{invisible}
  \pause

  \begin{itemize}[<+->]
    \item Amount of computation in training deep NNs
          increases exponentially (double every 3.4 months)
          \cite{openai2019}
    \item We'll run out of available computation (and
          energy) eventually
    \item Massively parallel, energy efficient and scalable
          systems are optimal for training NNs
  \end{itemize}
\end{frame}
% }}}

% What is tensorflow? {{{
\begin{frame}[fragile]
  \frametitle{What is tensorflow? And why the subtitle}
  \setbeamercovered{invisible}
  \pause

  \begin{itemize}[<+->]
    \item TensorFlow: Large-Scale Machine Learning on
          Heterogeneous Distributed Systems \cite{tf_2015}
    \item Basically: abstraction over various hardware and
          software libraries and APIs (CPUs, GPUs, TPUs,
          Eigen, MPI, CUDA, OpenCL, \dots)
    \item ``Easiest'' way to add new tensorflow backend? XLA
          (\url{https://www.tensorflow.org/xla})
    \item Instead: backend for keras (\url{https://keras.io})
    \item Using high level conceptual graph (the actual
          layers of the NN) instead of low level
          computational graph of tensorflow
  \end{itemize}
\end{frame}
% }}}

% Challenges {{{
\begin{frame}[fragile]
  \frametitle{Challenges}
  \setbeamercovered{invisible}
  \pause

  \begin{itemize}[<+->]
    \item Writing scientific programs is hard
    \item Writing programs for embedded hardware is hard
    \item Both together? \dots
  \end{itemize}
\end{frame}
% }}}

% Overcoming them {{{
\begin{frame}[fragile]
  \frametitle{Overcoming them}
  \setbeamercovered{invisible}
  \pause

  \begin{itemize}[<+->]
    \item Prepare myself well
    \item Taking stimulants and don't sleep for three
          months
  \end{itemize}
\end{frame}
% }}}

% References {{{
\begin{frame}
  \frametitle{References}
  \bibliography{literature.bib}
\end{frame}
% }}}

\end{document}
