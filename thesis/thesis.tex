\documentclass[]{article}

%\usepackage{epcc}
\usepackage{jmlr2e}
%\usepackage[hyphens]{url}
%\PassOptionsToPackage{hyphens}{url}
%\usepackage[colorlinks=false, hidelinks]{hyperref}
\usepackage{amsmath}
\usepackage[toc,page]{appendix}
\usepackage[table]{xcolor}
\usepackage[marginparsep=30pt]{geometry}
\usepackage{stmaryrd}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{tabu}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{fancyref}
\usepackage{relsize}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{diagbox}
\usepackage{multirow}
\usepackage{slashbox}
\usepackage{graphics}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{csquotes}

\usetikzlibrary{%
    arrows,
    arrows.meta,
    decorations,
    backgrounds,
    positioning,
    fit,
    petri,
    shadows,
    datavisualization.formats.functions,
    calc,
    shapes,
    shapes.multipart,
    matrix,
    plotmarks
}

\usepgfplotslibrary{fillbetween, statistics, dateplot}

\pgfplotsset{%
  compat=1.3,
  every non boxed x axis/.style={%
  enlarge x limits=false,
  x axis line style={}%-stealth},
  },
  every boxed x axis/.style={},
  every non boxed y axis/.style={%
  enlarge y limits=false,
  y axis line style={}%-stealth},
  },
  every boxed y axis/.style={},
}

\renewcommand{\labelenumii}{\theenumii}
\renewcommand{\theenumii}{\theenumi.\arabic{enumii}.}

\bibliographystyle{plainnat}
\bibpunct{(}{)}{;}{a}{,}{,}

\newenvironment{declaration}
{\centerline{\large\bf Declaration}\vspace{0.7ex}%
  \bgroup\leftskip 20pt\rightskip 20pt\noindent\ignorespaces}%
{\par\egroup\vskip 0.25ex}


\def\title{Deep Learning on SpiNNaker}
\def\author{Jonas Fassbender \\ \textit{jonas@fassbender.dev}}
\date{}

\ShortHeadings{Jonas Fassbender}{\title}

\begin{document}

% titlepage {{{
\begin{titlepage}

\begin{flushleft}
	\vspace*{-1cm}
	\includegraphics[scale=0.15]{logos/logo_black.pdf}\\
	\vspace*{1cm}
\end{flushleft}
\begin{flushright}
	\vspace*{-3cm}
	\includegraphics[scale=0.2]{logos/crest_bw.pdf}\\
	\vspace*{1cm}
\end{flushright}


%\EPCCheaderLogos
\null

\begin{center}
\begin{Huge}
\textbf{\title}
\end{Huge}
~\\
~\\
~\\
\textit{\Large {\LARGE M}ASTER {\LARGE T}HESIS}
~\\
~\\
~\\
\begin{Large}
\begin{tabu} to \textwidth {Xr}
Jonas Fassbender
&\href{mailto:jonas@fassbender.dev}{jonas@fassbender.dev}
\end{tabu}
\end{Large}
~\\
~\\
~\\
\begin{large}
In the course of studies

\textit{{\Large H}IGH {\Large P}ERFORMANCE {\Large C}OMPUTING WITH {\Large D}ATA {\Large S}CIENCE}
~\\
~\\
~\\
For the degree of

\textit{{\Large M}ASTER OF {\Large S}CIENCE}
~\\
~\\
~\\
The University of Edinburgh
~\\
~\\
~\\
\begin{tabular}{rl}
  First supervisor: &Caoimh√≠n Laoide-Kemp \\
                    &EPCC, University of Edinburgh \\
  &\\
  Second supervisor: &Dr Kevin Stratford \\
                     &EPCC, University of Edinburgh \\
  &\\
  Third supervisor: &Dr Alan Stokes \\
                    &APT, University of Manchester \\
\end{tabular}
~\\
~\\
~\\
Edinburgh, August 2020
\end{large}
\end{center}
\end{titlepage}
% }}}

\pagenumbering{roman}

% here thanks

% declaration {{{
\hspace{0pt}
\vfill

\begin{declaration}
I declare that this dissertation was composed by myself, that the work
contained herein is my own except where explicitly stated otherwise in
the text, and that this work has not been submitted for any other
degree or professional qualification except as specified.
~\\
~\\
~\\
\begin{tabu}{Xc}
  &Jonas Fassbender \\
  &August 2020
\end{tabu}
\end{declaration}

\vfill
\hspace{0pt}
% }}}

\newpage

% abstract {{{
\hspace{0pt}
\vfill

\begin{abstract}
\end{abstract}

\vfill
\hspace{0pt}
% }}}

\newpage

\tableofcontents

\newpage

\listoffigures

\newpage

% listoftables

\pagenumbering{arabic}

% fancy page (maybe above arabic -- depends on page numbers)

\section{Introduction}

Deep learning is revolutionizing the world.
It has become part of our daily lives as consumers, powering major
software products---from recommendation systems and translation tools
to web search \citep{lecun_et_al_2015}.
Major breakthroughs in fields like computer vision
\citep{krizhevsky_et_al_2012} or natural language
processing \citep{hinton_et_al_2012} were achieved through the use of
deep learning.
It has emerged as a driving force behind discoveries in numerous
domains like particle physics \citep{ciodaro_et_al_2012},
drug discovery \citep{ma_et_al_2015}, genomics
\citep{leung_et_al_2014} and gaming \citep{silver_et_al_2016}.

Deep learning has become so ubiquitous that we are changing the
way we build modern hardware to account for its computational demands.
From the way edge devices like mobile phones or embedded systems are
built \citep{deng_2019} and modern CPUs \citep{perez_2017} to
specialized hardware designed only for deep learning models, such
as Google's tensor processing unit (TPU) \citep{jouppi_et_al_2017} or
NVIDIA's EGX Edge AI platform \citep{boitano_2020}.
Whole state-of-the-art supercomputers are built solely for deep
learning.
An example would be a supercomputer built by Microsoft for OpenAI,
which is part of the Azure cloud \citep{langston_2020}.

Hardware manufacturer are faced with a major challenge in meeting the
computational demands arising from inference, and more importantly,
training deep learning models.
OpenAI researchers have estimated that the computational costs of
training increases exponentially; approximately every 3.4 months the
cost doubles \citep{amodei_et_al_2019}.
\citet{amodei_et_al_2019} claims the deep reinforcement learning agent
AlphaGo Zero---the successor of the famous AlphaGo program, which
was able to beat Go world champion Lee Sedol
\citep{silver_et_al_2017}---to be the system  with the highest
computational demands of approximately 1850 petaflop/s-days.
AlphaGo Zero was trained for 40 days on a machine with 4 TPUs
\citep{silver_et_al_2017}.
With the end of Moore's Law \citep{loeffler_2018}, chip makers have to
get creative in scaling up computing, the same way machine learning
researchers are scaling up their models \citep{simonite_2016}.
Therefore production and research into new hardware designs for deep
learning are well on the way.

Another field which has high computational demands for very specific
tasks and algorithms is computational neuroscience.
Computational neuroscience has long been linked to deep learning,
which has its origin in research done by neuroscientists
\citep{mcculloch_et_al_1943}.
While in the recent past deep learning research has been more focused
on mathematical topics like statistics and probability theory,
optimization or linear algebra, researchers are again looking to
neuroscience to further improve the capabilities of deep
learning models \citep{marblestone_et_al_2016}.

But the algorithms developed by computational neuroscientists are not
the only aspect drawing attention from the deep learning community.
Computational neuroscience has a long standing history of
developing custom hardware for the efficient modeling of the human
brain, so called neuromorphic computing. Neuromorphic computing---a
computer architecture inspired by the biological nervous system---has
been around since the 1980s \citep{mead_1989}.
Today, neuromorphic computers are being developed to meet the
demands for efficient computing needed to run large-scale
spiking neural networks used for modeling brain
functions \citep{furber_2016}.
While being developed mainly for the task of modeling the human brain,
deep learning has been linked to neuromorphic computing,
especially in the context of commercial usability \citep{gomes_2017}.
Both the low energy demands of neuromorphic computers---such as IBM's
True North \citep{cassidy_et_al_2013} or The University of
Manchester's Spiking Neural Network Architecture (SpiNNaker)
\citep{furber_et_al_2006}---and their
scalability and massive-parallelism are intriguing for two very
important use cases of deep learning:
(\romannumeral 1) edge computing, for example robotics
and mobile devices, (\romannumeral 2) supercomputers and the
cloud-era \citep{gomes_2017}.

This thesis investigates the performance of SpiNNaker machines for
deep learning by training the state-of-the-art computer vision model
ResNet-50 \citep{he_et_al_2015} under the closed division rules of the
MLPerf benchmark \citep{mattson_et_al_2019}.
In order to benchmark ResNet-50 on SpiNNaker a prototypical
implementation was developed as part of this thesis.

\begin{itemize}
  \item here a paragraph about the results
\end{itemize}

Section~\ref{sec:background} presents the background of this thesis.
An introduction to deep learning is given in
Section~\ref{subsec:intro_dl}, as well as an overview
of the benchmark in Section~\ref{subsec:intro_bench}.
Section~\ref{subsec:intro_spinn} describes the SpiNNaker architecture
and compares it to current deep learning hardware.
Related work can be found in Section~\ref{sec:related_work}.
Section~\ref{sec:SpiDNN} presents the architecture of the
prototype developed for benchmarking and Section~\ref{sec:benchmark}
presents the benchmarks and its results.
In Section~\ref{sec:discussion} the results of the benchmark are
discussed, as well as the development process.
Section~\ref{sec:conclusion} contains the conclusion, while
Section~\ref{sec:next_steps} outlines the next steps for further
increasing the performance of SpiNNaker by enhancing the
prototype.


\section{Background} % {{{
\label{sec:background}

This section summarizes the background knowledge needed in the
following sections.
First a short introduction to deep learning is given in
Section~\ref{subsec:intro_dl}.
The main focus lies on the basic concepts and those important for
computer vision and therefore the prototype developed as part of this
thesis.
Next, Section~\ref{subsec:intro_bench} outlines the context of the
conducted benchmark presented in Section~\ref{sec:benchmark}.
Lastly the SpiNNaker neuromorphic computer architecture is described
in Section~\ref{subsec:intro_spinn}.
SpiNNaker is also compared against the two state-of-the-art hardware
solutions for deep learning which currently produce the best
performance in training and inference, namely general purpose
graphical processing units (GPGPUs) and Google's tensor processing
unit (TPU).

\subsection{An Introduction to Deep Learning} % {{{
\label{subsec:intro_dl}

While it may seem that deep learning is a recent development in the
field of artificial intelligence---due to all the hype and all
the announced breakthroughs---it is actually around since the 1940s.
\citet{mcculloch_et_al_1943} first described the McCulloch-Pitts
neuron as a simple mathematical model of a biological neuron, which
should mark the origin of what today is known as deep learning.
The history of deep learning can be broken down into three distinct
phases and only during the last phase the methodology is
called deep learning; arguably the reason why deep learning seems to
be a new development.

The first phase, where deep learning was known as cybernetics, ranged
from the 1940s to the 1960s \citep{goodfellow_et_al_2016}.
Like stated above, it was the time where the first biologically
inspired representations of neurons where developed.
\citet{rosenblatt_1958} presents the first model, a single trainable
artificial neuron known as the perceptron (see
Figure~\ref{fig:perceptron}).
Today's perceptron receives a real-valued $n$-vector $\mathbf{x}$ of
\textit{input} signals and builds the dot product with another
real-valued $n$-vector known as \textit{weights} $\mathbf{w}$:
$\mathbf{x}\cdot\mathbf{w} = \sum_{i=0}^{n}x_iw_i$.
The \textit{bias} $b$ is added to the dot product.
$\mathbf{x} \cdot \mathbf{w} + b$ is then passed to the
\textit{activation function} $g$---some fixed transformation function
appropriate for the application domain---and
$y = g(\mathbf{x} \cdot \mathbf{w} + b)$ is the output of the
perceptron.

During supervised learning, we have a set of \textit{examples}.
Each example consists of an \textit{input} vector $\mathbf{x}$ and a
associated \textit{label} $y$ generated by an unknown function
$f^*(\mathbf{x})$.
A perceptron can be trained to approximate $f^*(\mathbf{x})$.
We can describe a perceptron as the mathematical function $y =
f(\mathbf{x};\mathbf{w}, b) = g(\mathbf{x} \cdot \mathbf{w} + b)$.
$f(\mathbf{x};\mathbf{w}, b)$ is known as a
\textit{(statistical) model} with
$\mathbf{w}$ and $b$ as its \textit{trainable parameters}
which are trained/learned in order to approximate $f^*$ with $f$.
How a network of perceptrons---a more complex statistical model better
suited for real world applications---is trained will be explained
below.

\begin{figure}
	\begin{center}
	\begin{tikzpicture}[dot/.style={circle,draw}]
		\node at (3,0) (out) {$y$};
		\node at (0,0) [dot] (neuron) {$\mathbf{x} \cdot \mathbf{w} + b$}
			edge[->] node[above]{$g$} (out);
		\node at (-3,4) [dot] {$x_1$}
			edge[->] (neuron);
		\node at (-3,2) [dot] {$x_2$}
			edge[->] (neuron);
		\node at (-3,0) [dot] {$x_3$}
			edge[->] (neuron);
		\node at (-3,-4) [dot] {$x_n$}
			edge[->] (neuron);
		\node at (-3,-2) [] {\vdots};
	\end{tikzpicture}
	\end{center}
	\caption {Schema of a perceptron.}
	\label{fig:perceptron}
\end{figure}

The second historical phase of deep learning is known as
connectionism (1980s-1990s) \citep{goodfellow_et_al_2016}.
Its main contributions to today's knowledge was the backpropagation
algorithm \citep{rumelhart_et_al_1986} and the approach of parallel
distributed processing
\citep{rumelhart_et_al_1986a, rumelhart_et_al_1986b}, which provided a
mathematical framework around the idea that a large number of simple
computational units (e.g.\ the perceptron) can achieve intelligent
behavior when connected together \citep{goodfellow_et_al_2016}.
Backpropagation enabled the training of networks of perceptrons
organized in layers.
A layer consists of multiple perceptrons and the layers are connected
successively so that no cycle exists between perceptrons.
An artificial neural network with such an architecture is known as the
multilayer perceptron (MLP) or the feedforward artificial neural
network.
\citet{hornik_et_al_1989} demonstrated that a non-linear MLP can
overcome the famous XOR problem of a single layer perceptron
demonstrated in \citet{minsky_et_al_1969}.
Another major contribution of the phase of connectionism was the
neocognitron \citep{fukushima_1980}, the origin of today's
convolutional neural networks (CNNs)---which are the state-of-the-art
approach for building computer vision models---and the application of
the backpropagation algorithm to fully automate the training of CNNs
\citep{lecun_et_al_1989}.

\begin{figure}
\begin{center}
	\begin{tikzpicture}[dot/.style={circle,draw,minimum size = .5cm}]
		\node at(-4,5) {input layer};
		\node at(0,5) {hidden layer};
		\node at(4,5) {output layer};

		\node at(6,1) (oo1) {};
		\node at(6,-1) (oo2) {};

		\node at (4,1) [dot] (o1) {}
			edge[->] (oo1);
		\node at (4,-1) [dot] (o2) {}
			edge[->] (oo2);

		\node at (0,4) [dot] (h1) {}
			edge[black!40] (o1.west)
			edge[black!40] (o2.west);
		\node at (0,2) [dot] (h2) {}
			edge[black!40] (o1.west)
			edge[black!40] (o2.west);
		\node at (0,0) [dot] (h3) {}
			edge[black!40] (o1.west)
			edge[black!40] (o2.west);
		\node at (0,-2) [dot] (h4) {}
			edge[black!40] (o1.west)
			edge[black!40] (o2.west);
		\node at (0,-4) [dot] (h5) {}
			edge[black!40] (o1.west)
			edge[black!40] (o2.west);

		\node at (-4,2) [dot] (i1) {}
			edge[black!40] (h1.west)
			edge[black!40] (h2.west)
			edge[black!40] (h3.west)
			edge[black!40] (h4.west)
			edge[black!40] (h5.west);
		\node at (-4,0) [dot] (i2) {}
			edge[black!40] (h1.west)
			edge[black!40] (h2.west)
			edge[black!40] (h3.west)
			edge[black!40] (h4.west)
			edge[black!40] (h5.west);
		\node at (-4,-2) [dot] (i3) {}
			edge[black!40] (h1.west)
			edge[black!40] (h2.west)
			edge[black!40] (h3.west)
			edge[black!40] (h4.west)
			edge[black!40] (h5.west);

		\node at(-6,2) (ii1) {}
			edge[->] (i1);
		\node at(-6,0) (ii2) {}
			edge[->] (i2);
		\node at(-6,-2) (ii3) {}
			edge[->] (i3);
	\end{tikzpicture}
\end{center}
\caption {Schema of a MLP or feedforward neural network.}
\label{fig:mlp}
\end{figure}

\citet{goodfellow_et_al_2016} claims that the third and current phase
of deep learning---where the name deep learning was
established---starts with \citet{hinton_et_al_2006} describing a new
learning algorithm called greedy layer-wise pretraining, which they
applied to deep belief networks.
Greedy layer-wise pretraining was soon generalized to work with other
deep artificial neural network architectures
\citep{renzato_et_al_2006, bengio_et_al_2007}.
While these papers may have resulted in the term deep learning,
they were not the reason for the resurrected interest in this
methodology.
The two most important factors are the increase of available data
and computation.
The former enables better generalization while the latter allows
training bigger models which can solve more complex problems
\citep{goodfellow_et_al_2016}.


% TODO: interwove concepts into history (perceptron, backprop ? and
%       so forth)... maybe only for a few concepts... keep sgd, cnns
%       and such by themselves
%       figures

% here make clear difference between DL and spiking neural networks
It is from that time that another synonym of deep learning originates:
(deep) artificial neural networks.

\begin{enumerate}
  \item clarify that DNNs are statistical methods (glorified non-linear
        classifiers) not biological like SNNs
  \item concepts of the MLP:
    \begin{itemize}
      \item layers
      \item activations
      \item forward- and backward-pass
      \item SGD
      \item \dots
    \end{itemize}
  \item CNNs
\end{enumerate}

% }}}

\subsection{Benchmarking Deep Learning Systems for Computer Vision} % {{{
\label{subsec:intro_bench}

\begin{enumerate}
  \item short section about imagenet and ilsvrc and their importance
        for computer vision
  \item ResNet50 and residual stuff
  \item paragraph about MLPerf
\end{enumerate}

% }}}

\subsection{SpiNNaker as a Neuromorphic Computer Architecture} % {{{
\label{subsec:intro_spinn}

\begin{enumerate}
  \item describe spinnaker and the spinnaker architecture
  \item compare to other DL accelerators (GPGPUs and TPUs)
\end{enumerate}
% spinnaker architecture

% compare to other state of the art machine learning hardware

% why didn't we just implement a backend (e.g. tensorflow?)
% because architecture is so different (MACs vs. massive parallelism
% with small messages)

% }}}

% }}}


\section{Related Work} % {{{
\label{sec:related_work}

\begin{enumerate}
  \item SNNToolbox for translating DNNs to SNNs (only inference)
  \item TrueNorth has a paper about its DL implementation
  \item (optional) The 2011 paper about mapping MLP's and recurrent
    networks onto SpiNNaker
\end{enumerate}

% }}}


\section{Deep Learning on SpiNNaker}
\label{sec:SpiDNN}

\begin{itemize}
  \item concepts (layers, neurons, \dots)
  \item partitions and how that allows me to use min keys to discern
    between what I have received
  \item communication structure (partitions and global partition manager)
  \item ping-pong
  \item graph structure (especially focused on edge and host--SpiNN
    communication)
  \item interpreting neurons as domain decomposition over linear algebra
    compute graph
  \item backward pass: gradients computed two times so comm fabric is
    not overly used by unique partitions
  \item How I crushed $n$d-kernels into a single blog of weights (same
    for 2D convolutions even though less interesting)
\end{itemize}

\section{Benchmark}
\label{sec:benchmark}

\section{Discussion}
\label{sec:discussion}

\begin{itemize}
  \item space used inefficiently (cores and memory) $\rightarrow$ better
    domain decomposition
\end{itemize}

\section{Conclusion}
\label{sec:conclusion}

\section{Next Steps}
\label{sec:next_steps}

\begin{itemize}
  \item multiple copies of the same network on the same machine
    $\rightarrow$ use all resources available
  \item better domain decomposition (SpiNNaker application graph or
    custom solution (application graph not helpful for neurons which
    become too big))
  \item smart algorithms vs.\ integrating with state-of-the-art libraries
    (investing time in stuff like SLIDE and the one paper by the Austrian
    guys about sparse connections explicitly mentioning SpiNNaker and
    neuromorphic chips or rather work on a trans-/compiler
    that efficiently translates linear algebra operations (like TF,
    PyTorch,\dots) onto SpiNNaker)
  \item integrate into compiler projects like Apache-TVM, XLA, Glow,
   nGraph, etc.
  \item implementing ONNX spec to make it easy for developers to use
    SpiNNaker (develop in PyTorch $\rightarrow$ run on SpiNNaker)
\end{itemize}

\bibliography{library.bib}
\addcontentsline{toc}{section}{References}

\end{document}
